{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851afc8f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/james-trayford/WISA2023Notebooks/blob/main/STRAUSSdemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e75e67",
   "metadata": {},
   "source": [
    "Notebook prepared by **Dr James Trayford** - for queries please email [`james.trayford@port.ac.uk`](mailto:james.trayford@port.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ea738",
   "metadata": {},
   "source": [
    "To use this notebook (if you haven't already) you can first save a copy to your local drive by clicking `File > Save a Copy in Drive` and run on that copy. `Edit > Clear all outputs` on that copy should also ensure yopu have a clean version\n",
    " to start from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff444299",
   "metadata": {},
   "source": [
    "# **0. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756a420",
   "metadata": {},
   "source": [
    "We will be using the [STRAUSS code](https://github.com/james-trayford/strauss) for this activity\n",
    "\n",
    "<img src=\"https://github.com/james-trayford/strauss/blob/main/misc/strauss_logo.png?raw=true\">\n",
    "\n",
    "For reference, you can read an overview of the code (as well as detailed documentation) [at this link](https://strauss.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0516bd5",
   "metadata": {},
   "source": [
    "`strauss` is an open source, object-oriented python library intended to be a flexible toolkit and engine for sonification, allowing detailed low-level control over the sonification process. Simultaneously, casual users can quickly hear their data, adapting a library of python notebook templates for a range of applications.\n",
    "\n",
    "By analogy to visualisation, the intention is to provide something akin to a plotting library. A library allows users to make a variety of simple plots easily, but also the option to control all aspects of plots and adapt them to the intricacies of their data, for optimal presentation.\n",
    "\n",
    "By adopting a general approach, strauss is intended to sonify any form of data for users with differing expertise. strauss is work in progress, and benefits form user feedback - filling in this feedback will be very useful in making the code better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974b5b0",
   "metadata": {},
   "source": [
    "# 0.1 This notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d65f78",
   "metadata": {},
   "source": [
    "This notebook will demonstrate some of the ways in which `strauss` can be applied to sonify solar data. Alternative options may be demonstrated with commented out code ( i.e. lines of actual code preceded by `#`) - feel free to try these! Generally the goal of this notebook is to give some open examples to explore the code and experiment, so please do so! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbe8d3",
   "metadata": {},
   "source": [
    "***Throughout, we will use the pencil emoji, \"✏️\", to indicate parameters you might want to experiment with...***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1082f27",
   "metadata": {},
   "source": [
    "# 1. Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90520da7",
   "metadata": {},
   "source": [
    "First, let's install `strauss`! Just run the code cell below.\n",
    "\n",
    "*We will use the `spectraliser` development branch for this notebook to play with some experimental features.* \n",
    "\n",
    "Install can take a while - but you should only need to run it once!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22361e63",
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip --quiet install git+https://github.com/james-trayford/strauss.git@spectraliser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3f5d9",
   "metadata": {},
   "source": [
    "and also make a local copy of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " !git clone https://github.com/james-trayford/strauss.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa1ec9",
   "metadata": {},
   "source": [
    "Make plots appear in-line by default, import the modules we need, and set some figure defaults...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.io import readsav \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "from scipy.signal import savgol_filter as sgf\n",
    "matplotlib.rcParams.update({'font.size': 14, 'figure.figsize': (12,6)})\n",
    "\n",
    "# strauss imports\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Events, Objects\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "from strauss.generator import Sampler, Synthesizer, Spectralizer\n",
    "from strauss import sources as Sources \n",
    "import strauss\n",
    "\n",
    "# modules to display in-notebook\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import display, Markdown, Latex, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7354e10",
   "metadata": {},
   "source": [
    "# 2. Getting the data and fitting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfb2b0",
   "metadata": {},
   "source": [
    "We'll be handling line-fit data today which is relative light and easy to process in this environment - though most of these ideas apply to the raw data set too.\n",
    "\n",
    "First, let's run a script to download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafe1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"./solar_data\"\n",
    "\n",
    "path = os.path.realpath(outdir)\n",
    "if not glob.glob(outdir): \n",
    "  os.mkdir(path)  \n",
    "    \n",
    "fname = \"WISA2023_STRAUSS_tutorial\"\n",
    "url = \"https://drive.google.com/uc?export=download&id=1xYb2ewmuB1ABlAcp0bwWCs89u__-qJ8g\"\n",
    "print(f\"Downloading files...\")\n",
    "with urllib.request.urlopen(url) as response, open(f\"{path}/{fname}\", 'wb') as out_file:\n",
    "  data = response.read() # a `bytes` object\n",
    "  out_file.write(data)\n",
    "\n",
    "print(f\"Unzipping files to {outdir}/solar_data ...\")\n",
    "with zipfile.ZipFile(f\"{outdir}/{fname}\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(f\"{outdir}\")\n",
    "\n",
    "print(f\"Clearing up...\")\n",
    "os.remove(f\"{path}/{fname}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f03b56",
   "metadata": {},
   "source": [
    "Now lets read this into a data dictionary (\"`dict`\") object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['MgII','SiIV']\n",
    "wlens = [2796, 1403]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for l in lines:\n",
    "    f = readsav(f'solar_data/WISA2023/maxval_2014-04-03{l}.sav')\n",
    "    \n",
    "    data[l] = {}\n",
    "\n",
    "    # clean up NaNs\n",
    "    mdopr_valid = ~np.isnan(f['mdopr'])\n",
    "    mdopb_valid = ~np.isnan(f['mdopb'])\n",
    "    mnth_valid = ~np.isnan(f['mnth'])\n",
    "    mint_valid = ~np.isnan(f['mint'])\n",
    "\n",
    "    # order data in time\n",
    "    tdopr_sort = np.argsort(f['tdopr'][mdopr_valid])\n",
    "    tdopb_sort = np.argsort(f['tdopb'][mdopb_valid])\n",
    "    tnth_sort = np.argsort(f['tnth'][mnth_valid])\n",
    "    tint_sort = np.argsort(f['tint'][mint_valid])\n",
    "\n",
    "    # Red shift velocities for Mg II [km/s]\n",
    "    data[l]['mdopr'] = f['mdopr'][mdopr_valid][tdopr_sort]\n",
    "    # Blue shift velocities for Mg II [km/s]\n",
    "    data[l]['mdopb'] = f['mdopb'][mdopb_valid][tdopb_sort]\n",
    "    \n",
    "    # Time positions for red shift velocities for Mg II [min]\n",
    "    data[l]['tdopr'] = f['tdopr'][mdopr_valid][tdopr_sort]\n",
    "    #  Time positions for blue shift velocities for Mg II [min]\n",
    "    data[l]['tdopb'] = f['tdopb'][mdopb_valid][tdopb_sort]\n",
    "    # Standard deviations for red shift velocities for Mg II [km/s]\n",
    "    data[l]['stddopr'] = f['stddopr'][mdopr_valid][tdopr_sort]\n",
    "    # Standard deviations for blue shift velocities for Mg II [km/s]\n",
    "    data[l]['stddopb'] = f['stddopb'][mdopb_valid][tdopb_sort] \n",
    "    # Non-thermal velocities for Mg II [km/s]\n",
    "    data[l]['mnth'] = f['mnth'][mnth_valid][tnth_sort]\n",
    "    # Times for the non-thermal velocities for Mg II [min]\n",
    "    data[l]['tnth'] = f['tnth'][mnth_valid][tnth_sort]\n",
    "    # Standard deviation for the non-thermal velocities for Mg II [km/s]\n",
    "    data[l]['stdnth'] = f['stdnth'][mnth_valid][tnth_sort]\n",
    "    # Integrated intensities for Mg II [DN]\n",
    "    data[l]['mint'] = f['mint'][mint_valid][tint_sort]\n",
    "    # Times for the integrated intensities for Mg II [min]\n",
    "    data[l]['tint'] = f['tint'][mint_valid][tint_sort]\n",
    "    \n",
    "    data[l]['vgridb'] = np.column_stack([np.linspace(-250,0,2000)]*data[l]['mdopb'].size)\n",
    "    data[l]['vgridr'] = np.column_stack([np.linspace(0,250,2000)]*data[l]['mdopr'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6c5d7",
   "metadata": {},
   "source": [
    "Let's now define a Gaussian function, so we can reproduce the fitted line profiles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ef47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    # Gaussian function to reproduce fitted line profiles \n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))/(sig * np.sqrt(2*np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41adf833",
   "metadata": {},
   "source": [
    "...and look at the Doppler velocity data for one line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a line 0 => MgII, 1 => SiIV\n",
    "l = lines[0]\n",
    "\n",
    "# show doppler velocity evolution\n",
    "plt.title(l)\n",
    "plt.scatter(data[l]['tdopb'], \n",
    "            data[l]['mdopb'])\n",
    "plt.scatter(data[l]['tdopr'], \n",
    "            data[l]['mdopr'])\n",
    "plt.xlabel('Time [min]')\n",
    "plt.ylabel('Doppler Velocity [km/s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e879f",
   "metadata": {},
   "source": [
    "Finally, we might also want to smooth the data to reduce noisy, short-time variations in trends when sonifying in certain contexts. This also allows us to interpolate the data, such that it is all on the same time grid. \n",
    "\n",
    "We smooth it on a chosen timescale, \"`tsmooth`\" (5 minutes by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine time grid for smoothing data\n",
    "tfine = np.linspace(0,96.5,10000)\n",
    "\n",
    "# dict for smoothed data\n",
    "sdata = {}\n",
    "\n",
    "# pick a smoothing timescale\n",
    "tsmooth = 5 # minutes\n",
    "\n",
    "for l in lines:\n",
    "    winlen = int(tsmooth/np.diff(tfine)[0])\n",
    "    winlen += 1-(winlen % 2)\n",
    "    sdata[l] = {}\n",
    "    \n",
    "    # smooth the data arrays onto a regular fine time grid\n",
    "    sdata[l]['mdopb'] = sgf(np.interp(tfine, data[l]['tdopb'], data[l]['mdopb']), winlen, 3)\n",
    "    sdata[l]['stddopb'] = sgf(np.interp(tfine, data[l]['tdopb'], data[l]['stddopb']), winlen, 3)\n",
    "    sdata[l]['mdopr'] = sgf(np.interp(tfine, data[l]['tdopr'], data[l]['mdopr']), winlen, 3)\n",
    "    sdata[l]['stddopr'] = sgf(np.interp(tfine, data[l]['tdopr'], data[l]['stddopr']), winlen, 3)\n",
    "    sdata[l]['mnth'] = sgf(np.interp(tfine, data[l]['tnth'], data[l]['mnth']), winlen, 3)\n",
    "    sdata[l]['stdnth'] = sgf(np.interp(tfine, data[l]['tnth'], data[l]['stdnth']), winlen, 3)\n",
    "    sdata[l]['mint'] = sgf(np.interp(tfine, data[l]['tint'], data[l]['mint']), winlen, 3)\n",
    "    \n",
    "    sdata[l]['vgridb'] = np.column_stack([np.linspace(-250,0,2000)]*tfine.size)\n",
    "    sdata[l]['vgridr'] = np.column_stack([np.linspace(0,250,2000)]*tfine.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9b755",
   "metadata": {},
   "source": [
    "Finally, lets plot all of that together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa01d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a line and blue ('b') or red ('r') shifted component to plot\n",
    "c = 'b'\n",
    "\n",
    "# plot some properties\n",
    "\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    l = lines[i]\n",
    "    print(f\"{l}: {c.upper()}-shifted component\")\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.add_subplot(221+i*2)\n",
    "    plt.title(l)\n",
    "    plt.scatter(data[l][f'tdop{c}'],data[l][f'mdop{c}'],s=5, label='Raw Frames')\n",
    "    plt.plot(tfine,sdata[l][f'mdop{c}'], zorder=9,lw=8, c='w')\n",
    "    plt.plot(tfine,sdata[l][f'mdop{c}'], zorder=10,lw=2,c='0.3', label =\"Moving Average\")\n",
    "    plt.legend(frameon=0)\n",
    "    plt.ylim(-150,3)\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('Doppler Velocity [km/s]')\n",
    "    fig.add_subplot(222+i*2)\n",
    "    plt.scatter(data[l][f'tdop{c}'],data[l][f'stddop{c}'],s=5)\n",
    "    plt.plot(tfine,sdata[l][f'stddop{c}'], zorder=9,lw=8, c='w')\n",
    "    plt.plot(tfine,sdata[l][f'stddop{c}'], zorder=10,lw=2,c='0.3',)\n",
    "    plt.ylabel('Standard Deviation [km/s]')\n",
    "    plt.ylim(-2,45)\n",
    "    plt.xlabel('Time [min]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24358d",
   "metadata": {},
   "source": [
    "# 3. Sonification: Abstracted approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d1e22",
   "metadata": {},
   "source": [
    "In this section, we use the line fitting parameters mapped to different properties of sound, to convey their evolutino over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db99d3",
   "metadata": {},
   "source": [
    "## 3.1 Listening to the Raw, discrete, 1D Data Series using `Events`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8616488d",
   "metadata": {},
   "source": [
    "Here we will sonify solar line-fit data as a ***one-dimensional time series*** , where some ***sound property*** is varied with ***time*** in the ***sonification***, in the same way that **doppler velocity**, varies with ***time*** in the ***evolving line-profile fits*** (early in the sonification is earlier times, later is later times). This approach in general is covered in this [activity workbook](https://github.com/james-trayford/AudibleUniverseWorkbooks/blob/group4/STRAUSSdemo.ipynb), for the 2022 _'Audible Universe'_ meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960c314",
   "metadata": {},
   "source": [
    "In `strauss` we could treat each ***doppler velocity*** data point in the spectra as separate audio `Events`, with an occurence `time` mapped from their ***observation time***. \n",
    "\n",
    "However, articulating each data point as a separate ***note*** for ***many thousands*** of data points can require long and drawn-out sonifications. \n",
    "\n",
    "Here we demonstrate this approach with just a portion of the data points (staying within `Colab`'s RAM limitations for unpaid users 🤫). We use the `Synthesizer` object with the `pitch_mapper` preset by default - this has a default pitch range of ***two octaves*** (a factor of 4 in frequency) and we pick an `E3` note (165 Hz) as the base (lowest) frequency.\n",
    "\n",
    "We will hear the **doppler velocity** at each instant as a `pitch`, with their observation time mapped to the occurence `time` in the sonification (moving from early to late). We can hear the noisy beahaviour, but also general trends, particular the rising blue-shifts at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae99576",
   "metadata": {},
   "source": [
    "### 3.1.1 Atonal Example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c5b57",
   "metadata": {},
   "source": [
    "Allowing the pitch to freely vary with doppler velocity, we here an exact mapping between relative frequency and the doppler shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19416cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Sonifying in 1D using '`Events`' object (atonal):\"))\n",
    "\n",
    "# Pick a line... ✏️\n",
    "l = 'MgII'\n",
    "\n",
    "# show data again, for reference\n",
    "plt.scatter(data[l]['tdopb'], -data[l]['mdopb'], s=4)\n",
    "plt.ylabel('Doppler Blue-Shift Velocity [km/s]')\n",
    "plt.xlabel('Time [m]')\n",
    "plt.show()\n",
    "\n",
    "%matplotlib notebook\n",
    "# specify the base notes used. In this example we use a single E3 note and \n",
    "# freely vary the pitch via the 'pitch_shift' parameter \n",
    "notes = [[\"E3\"]]\n",
    "\n",
    "# we could also just specify a particular frequency... ✏️\n",
    "# notes = [[150.]]\n",
    "\n",
    "score =  Score(notes, 30)\n",
    "\n",
    "\n",
    "maps = {'pitch':np.ones(data[l]['mdopb'].size),\n",
    "        'time': data[l]['tdopb'],\n",
    "        'pitch_shift':-data[l]['mdopb']}\n",
    "\n",
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "\n",
    "# set up synth (this generates the sound using mathematical waveforms)\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('pitch_mapper')\n",
    "\n",
    "# or maybe the sampler instead by uncommenting this block (this uses recorded audio clips)\n",
    "# generator = Sampler(sampfiles=\"./strauss/data/samples/mallets\")\n",
    "# generator.modify_preset({'phi': 0,'theta':0,})\n",
    "\n",
    "generator.modify_preset({'note_length':0.1,\n",
    "                         'volume_envelope': {'use':'on',\n",
    "                                             # A,D,R values in seconds, S sustain fraction from 0-1 that note \n",
    "                                             # will 'decay' to (after time A+D)\n",
    "                                             'A':0.02,    # ✏️ for such a fast sequence, using ~10 ms values \n",
    "                                             'D':0.04,    # ✏️ for such a fast sequence, using ~10 ms values\n",
    "                                             'S':0.,      # ✏️ decay to volume 0\n",
    "                                             'R':0.001}}) # ✏️ for such a fast sequence, using ~10 ms values\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch range is used...\n",
    "# setting 0 to 101 for pitch means the sonification is 1% longer than the final note position\n",
    "lims = {'time': ('0','100.333333'),\n",
    "        'pitch_shift': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Events(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "# soni.save('pitchpm.wav')\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a8f0d",
   "metadata": {},
   "source": [
    "### 3.1.2 \"Musical\" Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e3ff4",
   "metadata": {},
   "source": [
    "Instead, in this example restrict notes onto a (western) musical scale - the major pentatonic. Pitch is again mapped to doppler velocity, but now binned onto a discrete set of musical pitches. In some contexts, this may be preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### Sonifying in 1D using '`Events`' object (musical):\"))\n",
    "\n",
    "# Pick a line...\n",
    "l = 'MgII'\n",
    "\n",
    "# grab times and values for chosen line\n",
    "x = data[l]['tdopb']\n",
    "y = -data[l]['mdopb']\n",
    "\n",
    "# show data again, for reference\n",
    "plt.scatter(x, y, s=4)\n",
    "plt.ylabel('Doppler Velocity [km/s]')\n",
    "plt.xlabel('Time [min]')\n",
    "plt.show()\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# specify the notes used. \n",
    "\n",
    "# C major pentatonic\n",
    "notes = [[\"C3\",\"E3\",\"F3\",\"G3\",\"B3\",\"C4\",\"E4\",\"F4\",\"G4\",\"B4\",\"C5\",\"E5\",\"F5\",\"G5\",\"B5\"]]\n",
    "\n",
    "# or a whole-tone scale, (was it just a dream... a dream... a dream...)\n",
    "#\n",
    "# This is a symetrical scale and here also demonstrates using raw frequencies in Hz.\n",
    "# The whole tone scale uses 2 semitone jumps, what about minor thirds (3) fourths (5)\n",
    "# or fifths (7)? Specify `semitones` to change this.\n",
    "# `nint` specifies the number of intervals in the scale. Note a bigger semitone interval\n",
    "# will reach higher pitches (perhaps inaudible ones...) ✏️\n",
    "\n",
    "# semitones = 2.\n",
    "# nint = 10\n",
    "# notes = [100*2**(np.arange(nint)*(semitones/12))]\n",
    "\n",
    "# ------\n",
    "# In this context, we also consider the `Score` optional parameter `pitch_binning`.\n",
    "#\n",
    "# This determines how we bin the 'pitch' quantity, which can be either:\n",
    "# - 'uniform':  the range of mapped values for 'pitch' are split into even bins\n",
    "#               representing  each of the scored notes\n",
    "# - 'adaptive': the range of mapped values for 'pitch' split by percentile. \n",
    "#               such that each interval is played approximately the same number of \n",
    "#               times\n",
    "# without specifying,  'adaptive' is used by default, but we specify 'uniform' here\n",
    "#\n",
    "# which is better for representing this data?\n",
    "\n",
    "# we specify 'uniform' pitch binning in the primary example... ✏️\n",
    "score =  Score(notes, 30, pitch_binning='uniform')\n",
    "\n",
    "# what about adaptive?\n",
    "#score =  Score(notes, 30, pitch_binning='adaptive')\n",
    "\n",
    "maps = {'pitch':y,\n",
    "        'time': x}\n",
    "\n",
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "\n",
    "# set up synth (this generates the sound using mathematical waveforms)\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('pitch_mapper')\n",
    "\n",
    "generator.modify_preset({'note_length':0.15,\n",
    "                         'volume_envelope': {'use':'on',\n",
    "                                             # A,D,R values in seconds, S sustain fraction from 0-1 that note \n",
    "                                             # will 'decay' to (after time A+D)\n",
    "                                             'A':0.02,    # ✏️ for such a fast sequence, using ~10 ms values \n",
    "                                             'D':0.04,    # ✏️ for such a fast sequence, using ~10 ms values\n",
    "                                             'S':0.,      # ✏️ decay to volume 0\n",
    "                                             'R':0.001}}) # ✏️ for such a fast sequence, using ~10 ms values\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch range is used...\n",
    "# setting 0 to 101 for pitch means the sonification is 1% longer than \n",
    "# the time needed to trigger each note - by making this more than 100%\n",
    "# we give all the notes time to ring out (setting this at 100% means\n",
    "# the final note is triggered at the momement the sonification ends)\n",
    "lims = {'time': ('0','101'),\n",
    "        'pitch_shift': ('0','100'),\n",
    "        'pitch': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Events(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dba9c",
   "metadata": {},
   "source": [
    "## 3.2 Listening to the smoothed line profile evolution using `Objects` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a1b1f",
   "metadata": {},
   "source": [
    "Now, we use the smoothed properties we calculated to map properties continuosly using the `Object` source type. \n",
    "\n",
    "We are considering the blue-shifted component of the `MgII` and `SiIV` lines together in a single sonification. Using stereo separation, we place the `MgII` `Object` source all the way left and `SiIV` `Object` source all the way right - _definitely helps to have headphones!_\n",
    "\n",
    "here we start the examples at the same base `pitch` and map doppler velocities to `pitch_shift`, so their divergence from being in tune tells us how strong the relative doppler shifts are.\n",
    "\n",
    "Optionally, we can also make each `Object` source multivariate by also encoding the doppler velocity ***standard deviation***  to another property of sound. Here we use the intensity of a volume low-frequency oscillator (LFO). This modulates the volume with a fast rhythmic pulse (12 Hz bty default), suh that  the pulse intensity increases with the standard deviation. In this way, we can hear the velocity and it's standard deviation simultaneously\n",
    "\n",
    "To turn this on, reference the \"✏️\" symbols below... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"stereo\"\n",
    "\n",
    "# length of the sonification in s ✏️\n",
    "length = 30.\n",
    "\n",
    "# show data for reference\n",
    "ear = ['left', 'right']\n",
    "for i in range(len(lines)):\n",
    "    l = lines[i]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.add_subplot(221+i*2)\n",
    "    plt.title(f\"{l} {ear[i]} ear\")\n",
    "    plt.plot(tfine,-sdata[l][f'mdop{c}'], zorder=10,lw=2,c='0.3', label =\"Moving Average\")\n",
    "    plt.ylim(-3, 150)\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('Blue-shift Velocity [km/s] -> to Pitch')\n",
    "    fig.add_subplot(222+i*2)\n",
    "    plt.plot(tfine,sdata[l][f'stddop{c}'], zorder=10,lw=2,c='0.3',)\n",
    "    plt.ylabel('Std. Deviation [km/s] -> to LFO depth')\n",
    "    plt.ylim(-2,45)\n",
    "    plt.xlabel('Time [min]')\n",
    "plt.show()\n",
    "\n",
    "# set up synth and turn on LP filter\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('pitch_mapper')\n",
    "generator.preset_details('pitch_mapper')\n",
    "\n",
    "doppler_mapping = 'pitch_shift'\n",
    "\n",
    "display(Markdown(f\"### Sonifying MgII (left) and SiIV (right) using '`pitch_shift`':\"))\n",
    "\n",
    "notes = [[\"A2\", \"A2\"]]\n",
    "score =  Score(notes, length)\n",
    "\n",
    "# \"True\" makes this a multivariate sonification where intensity of pulse is mapped to standard deviation... ✏️\n",
    "use_lfo =  False \n",
    "\n",
    "lfo_type = ['pitch', 'volume']\n",
    "lfo_idx = 1\n",
    "\n",
    "generator.modify_preset({'filter':'on',\n",
    "                        f\"{lfo_type[lfo_idx]}_lfo\": {\"use\": use_lfo, \n",
    "                                                     \"amount\":0, \n",
    "                                                     \"freq\":12, #  base LFO frequency in Hz (12) ✏️\n",
    "                                                     \"phase\":0}})\n",
    "\n",
    "maps = {'pitch':[0,1],\n",
    "        'time_evo':[tfine, tfine],\n",
    "        doppler_mapping : [(-sdata['MgII'][f'mdopb']), (-sdata['SiIV'][f'mdopb'])],\n",
    "        f'{lfo_type[lfo_idx]}_lfo/amount':[sdata['MgII'][f'stddopb'],sdata['SiIV'][f'stddopb']],\n",
    "        'phi':[0.25,0.75],\n",
    "       'theta':[0.5,0.5]}\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch and time range is used...\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        doppler_mapping: ('0','100'),\n",
    "        f'{lfo_type[lfo_idx]}_lfo/amount': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18211b5a",
   "metadata": {},
   "source": [
    "We can play around with some of these `evolvable` properties (listed below) here. Are all of these effective for this data? Could they be effective for other types of data representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### ***'Mappable'*** properties:\"))\n",
    "for m in Sources.mappable:\n",
    "  display(Markdown(f' * `{m}` '))\n",
    "\n",
    "display(Markdown(f\"### ***'Evolvable'*** properties:\"))\n",
    "for m in Sources.evolvable:\n",
    "  display(Markdown(f' * `{m}` '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b15e0c",
   "metadata": {},
   "source": [
    "As above, but now mapping blue-shift velocity to the cutoff frequency of a low-pass filter. This changes the timbre of each note. Because the fundamental pitches aren't changing, we choose two notes that are 'in tune' to represent the two lines a 'perfect fifth' apart.\n",
    "\n",
    "Again, there is a second mapping of standard deviation to pulse intensity (via a volume LFO), but this time it is turned on by default. Listen to how the combination of timbre and pulse intensity tells us a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44000ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"stereo\"\n",
    "\n",
    "# length of the sonification in s ✏️\n",
    "length = 30.\n",
    "\n",
    "# set up synth and turn on LP filter\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('default')\n",
    "generator.preset_details('default')\n",
    "\n",
    "# show data for reference\n",
    "ear = ['left', 'right']\n",
    "for i in range(len(lines)):\n",
    "    l = lines[i]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.add_subplot(221+i*2)\n",
    "    plt.title(f\"{l} {ear[i]} ear\")\n",
    "    plt.plot(tfine,-sdata[l][f'mdop{c}'], zorder=10,lw=2,c='0.3', label =\"Moving Average\")\n",
    "    plt.ylim(-3, 150)\n",
    "    plt.xlabel('Time [min]')\n",
    "    plt.ylabel('Blue-shift Velocity [km/s] -> to Cutoff')\n",
    "    fig.add_subplot(222+i*2)\n",
    "    plt.plot(tfine,sdata[l][f'stddop{c}'], zorder=10,lw=2,c='0.3',)\n",
    "    plt.ylabel('Std. Deviation [km/s] -> to LFO depth')\n",
    "    plt.ylim(-2,45)\n",
    "    plt.xlabel('Time [min]')\n",
    "plt.show()\n",
    "\n",
    "doppler_mapping = 'cutoff'\n",
    "\n",
    "display(Markdown(f\"### Sonifying MgII (left) and SiIV (right) using LP filter '`cutoff`':\"))\n",
    "\n",
    "notes = [[\"A2\", \"E3\"]]\n",
    "score =  Score(notes, length)\n",
    "\n",
    "# \"True\" makes this a multivariate sonification where intensity of pulse is mapped to standard deviation... ✏️\n",
    "use_lfo =  True \n",
    "\n",
    "lfo_type = ['pitch', 'volume']\n",
    "lfo_idx = 1\n",
    "\n",
    "generator.modify_preset({'filter':'on',\n",
    "                        f\"{lfo_type[lfo_idx]}_lfo\": {\"use\": use_lfo, \n",
    "                                                     \"amount\":0, \n",
    "                                                     \"freq\":12, #  base LFO frequency in Hz (12) ✏️\n",
    "                                                     \"phase\":0}})\n",
    "\n",
    "maps = {'pitch':[0,1],\n",
    "        'time_evo':[tfine, tfine],\n",
    "        doppler_mapping : [(-sdata['MgII'][f'mdopb']), (-sdata['SiIV'][f'mdopb'])],\n",
    "        f'{lfo_type[lfo_idx]}_lfo/amount':[sdata['MgII'][f'stddopb'],sdata['SiIV'][f'stddopb']],\n",
    "        'phi':[0.25,0.75],\n",
    "       'theta':[0.5,0.5]}\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch and time range is used...\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        doppler_mapping: ('0','100'),\n",
    "        f'{lfo_type[lfo_idx]}_lfo/amount': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims, param_lims={'cutoff': (0.2, 0.8)})\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937dba13",
   "metadata": {},
   "source": [
    "## 3.X A Side Note About Presets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b08c3",
   "metadata": {},
   "source": [
    "You can see all the parameters that make up the default `Synthesizer` preset in a pop-up window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a185856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat ./strauss/src/strauss/presets/synth/default.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae193b2",
   "metadata": {},
   "source": [
    "... as well as the other presets we might want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00705779",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -1 ./strauss/src/strauss/presets/synth/*.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac430036",
   "metadata": {},
   "source": [
    "We can modify these presets at runtime (as we do in various examples throughout this session), or even write our own presets in `.yml` format.\n",
    "\n",
    "The `generator.preset()` function also accepts a filepath to a custom presets, where any changed preset parameters replace those in the `default` preset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a92d58",
   "metadata": {},
   "source": [
    "# 4. Sonification: Spectral Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e04a6c",
   "metadata": {},
   "source": [
    "Haing covered some of these more abtracted approaches, let's consider a direct sonification of the spectrum or _\"Spectralisation\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b4280",
   "metadata": {},
   "source": [
    "## 4.1 Using the IFFT \"Spectraliser\" (fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bdea6",
   "metadata": {},
   "source": [
    "Now lets focus on a single line, and the red and blue shifted components around it, such that the relative shifts are directly audible. We can construct a regularly-spaced spectrum, and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299739b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a line... ✏️\n",
    "idx = 0\n",
    "l = lines[idx]\n",
    "\n",
    "print(f\"{l} components\")\n",
    "print(sdata[l]['mdopb'][0], sdata[l]['stddopb'][0])\n",
    "print(sdata[l]['mdopr'][0], sdata[l]['stddopr'][0])\n",
    "\n",
    "# many wavelength points as this technique is fast....\n",
    "wls = np.linspace(80, -110, 100000)\n",
    "\n",
    "# construct spectrum\n",
    "spec = gaussian(wls, sdata[l]['mdopb'][-1], sdata[l]['stddopb'][-1])\n",
    "spec += gaussian(wls, sdata[l]['mdopr'][-1], sdata[l]['stddopr'][-1])\n",
    "\n",
    "plt.plot(wls, spec)\n",
    "plt.xlabel(\"Doppler Velocity [km/s]\")\n",
    "plt.ylabel(\"Intensity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac059df",
   "metadata": {},
   "source": [
    "In the code we are now investigating a ***much*** faster but less flexible approach. This uses the discrete, _Inverse Fast Fourier Transform_ algorithm (IFFT).\n",
    "\n",
    "This will convert a spectrum, scaled to audible frequencies, and generate a signal directly between a maximum and minimum frequency range.\n",
    "\n",
    "This algorithm is thousands of times faster than the oscillator array approach _(bearing in mind the large overhead on displaying audio files in `Colab`, vs locally)_, but for now isn't an evolvable parameter... This is coming soon!\n",
    "\n",
    "For now, we just iterate through and evaluate the spectrum across the red and blue shifted components of a single line, and display each spectrum with it's sonification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9968890",
   "metadata": {},
   "source": [
    "✨Evolving IFFT spectralisation **coming soon...**✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f15875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up spectralizer generator\n",
    "generator = Spectralizer()\n",
    "\n",
    "# Lets pick the mapping frequency range for the spectrum... ✏️\n",
    "generator.modify_preset({'min_freq':200, 'max_freq':10000})\n",
    "\n",
    "score =  Score([['A2']], 1)\n",
    "\n",
    "display(Markdown(f\"### 'Spectralising' MgII and SiIV components at 3 snapshots\"))\n",
    "\n",
    "for i in range(sdata[l]['mdopb'].size)[::2499]:\n",
    "    \n",
    "    spec = gaussian(wls, sdata[l]['mdopb'][i], sdata[l]['stddopb'][i])\n",
    "    spec += gaussian(wls, sdata[l]['mdopr'][i], sdata[l]['stddopr'][i])\n",
    "    \n",
    "    # set up spectrum and choose some envelope parameters for fade-in and fade-out\n",
    "    maps = {'spectrum': [spec], 'pitch':[1],\n",
    "            'volume_envelope/D':[0.5], \n",
    "            'volume_envelope/S':[0.], \n",
    "            'volume_envelope/A':[0.01]}\n",
    "\n",
    "    # again, use maximal range for the mapped parameters\n",
    "    lims = {'spectrum': ('0','100')}\n",
    "\n",
    "    # set up source\n",
    "    sources = Events(maps.keys())\n",
    "    sources.fromdict(maps)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    \n",
    "    plt.plot(wls,spec)\n",
    "    plt.xlabel(\"Doppler Velocity\")\n",
    "    plt.ylabel(\"Intensity\")\n",
    "    plt.show()\n",
    "    \n",
    "    dobj = soni.notebook_display()\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c540ed8",
   "metadata": {},
   "source": [
    "## 4.2 Using an array of oscillators (slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e6544",
   "metadata": {},
   "source": [
    "Here, we convert the frequencies representing these two spectral lines directly to oscillators art audible frequencies, that increase involume to represent their flux density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3698f2",
   "metadata": {},
   "source": [
    "First, we reconstruct the line spectrum representing the `SiIV` and `MgII` combination, using the fitting parameter data provided. These are mapped onto musical notes a _\"perfect fifth\"_ apart, such that these sound 'in tune' without any relative shift, but detuned as their blueshifts diverge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7dc3b",
   "metadata": {},
   "source": [
    "In this example we manipulate the data somewhat; scaling up the relative doppler shifts by a factor \"`scale`\" so that these frequency changes are audible to most people. We also apply a \"`contrast`\" to the intensities to control the relative power of each line (and ensure both are well audible)\n",
    "\n",
    "Generally, this approach allows us to smoothly vary spectra in time, but is relatively slow compared to the IFFT technique that is under construction in STRAUSS (see §4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3e5 # speed of light in km/s\n",
    "npoints = 500 # number of frequency points per line\n",
    "\n",
    "# subjective parameters\n",
    "scale = 500 # factor to scale up frequency variation! ✏️\n",
    "contrast = 0.5 # index to raise the intensties by. 0 < contrat <= 1 will ✏️\n",
    "notes = [300, 600*4/3]  # representative notes in Hz for each line ✏️\n",
    "\n",
    "wavs = []\n",
    "fluxes = []\n",
    "\n",
    "for i in range(len(wlens)):\n",
    "    z = -sdata[lines[i]]['mdopb']*scale/c\n",
    "    std = sdata[lines[i]]['stddopb']*scale/c\n",
    "    wavpls = (z + 1).T*wlens[i] - 10*std\n",
    "    wav = np.linspace(*np.percentile((z + 1).T*wlens[i] + np.expand_dims([-5*std, 5*std],1)*wlens[i], [0,100]),\n",
    "                      npoints)\n",
    "    wav *= notes[i]/wlens[i]\n",
    "    wavs.append(wav)\n",
    "    fluxes.append(gaussian(np.column_stack([wav]*z.size), (1+z)*notes[i], std*notes[i])*sdata[lines[i]]['mint']**contrast)\n",
    "    \n",
    "wavs = np.hstack(wavs)\n",
    "fluxes = np.vstack(fluxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519c059",
   "metadata": {},
   "source": [
    "and sonify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"stereo\"\n",
    "\n",
    "# length of the sonification in s\n",
    "length = 30.\n",
    "\n",
    "# set up synth and turn on LP filter\n",
    "generator = Synthesizer()\n",
    "generator.load_preset('spectraliser')\n",
    "generator.preset_details('spectraliser')\n",
    "\n",
    "display(Markdown(f\"### 'Spectralising' evolving MgII (left) and SiIV (right) blue-shift components (slow)\"))\n",
    "\n",
    "score =  Score([list(wavs)], length)\n",
    "\n",
    "maps = {'pitch':list(range(wavs.size)),\n",
    "        'time_evo':[tfine[:]]*wavs.size,\n",
    "        'volume':list(fluxes[:,:]),\n",
    "        'phi':list(0.25 + 0.5*wavs/wavs.max()),\n",
    "        'theta':[0.5]*wavs.size}\n",
    "\n",
    "# set 0 to 100 percentile limits so the full pitch and time range is used...\n",
    "lims = {'time_evo': ('0','100'),\n",
    "        'volume': ('0','100'),\n",
    "        'pitch':('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Objects(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "dobj = soni.notebook_display()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6fce8",
   "metadata": {},
   "source": [
    "# 6. Sandbox!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96140edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442e685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d665363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c57ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
